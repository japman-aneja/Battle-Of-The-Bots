{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4BQVnaAHC4F"
      },
      "source": [
        "## PyTorch Tutorial!!!\n",
        "In this assignment, you will be familiarized with the usage of the PyTorch library and how to build a model in two ways  \n",
        "It's quite similar to TensorFlow\n",
        "*   using the inbuilt layers in pytorch\n",
        "*   using custom layers to replicate the same result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Co1Y3oSoAqHp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o30DmRgozsmT",
        "outputId": "bb140f73-70c9-46e0-ffc1-e1cdf3544e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Using the GPU if it exists\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n682ZxROHh_1"
      },
      "source": [
        "### Loading and preprocessing the Data\n",
        "We will directly be using the dataset included in literally any library that exists. MNIST really is THAT popular.  \n",
        "Link: https://docs.pytorch.org/vision/0.9/datasets.html#mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8zrkUXY8AvtN"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6W4VEerGYJ8"
      },
      "source": [
        "## Making a simple feedforward network\n",
        "\n",
        "The following is a simple feedforward model with three layers:\n",
        "* a flatten layer to convert our 28x28 images into a single array of length 784\n",
        "* a dense layer of 128 neurons with the relu activation function\n",
        "* finally a dense layer of 10 neurons with the softmax activation to get a distribution between the digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "SequentialNet = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhb44jOezsmW"
      },
      "source": [
        "### Training and Testing loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JLSYJir_zsmX"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train(model, loader, optimizer, loss_fn, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Testing loop\n",
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aPQN3x4zsmX"
      },
      "source": [
        "### Training the sequential model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC-0YFJRzsmX",
        "outputId": "5ae67fad-69c6-4ca5-837f-5fdb44650ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training SequentialNet\n",
            "Epoch 1, Loss: 377.0540\n",
            "Epoch 2, Loss: 181.1596\n",
            "Epoch 3, Loss: 127.5819\n",
            "Epoch 4, Loss: 104.1927\n",
            "Epoch 5, Loss: 88.6052\n",
            "Accuracy: 96.55%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining SequentialNet\")\n",
        "sequential_model = SequentialNet.to(device)\n",
        "optimizer_seq = optim.Adam(sequential_model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train(sequential_model, train_loader, optimizer_seq, loss_fn)\n",
        "test(sequential_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCEMWK1KLZDT"
      },
      "source": [
        "### Manually building the same network from scratch\n",
        "You can use the simple sequential model we described above as a reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zw53cAmELYJK"
      },
      "outputs": [],
      "source": [
        "# Custom model\n",
        "class ManualNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ManualNet, self).__init__()\n",
        "        # TODO: Define your paramters using nn.Parameters (the layers)\n",
        "        self.w1 = nn.Parameter(torch.randn(784, 128) * 0.01)\n",
        "        self.b1 = nn.Parameter(torch.zeros(128))\n",
        "        self.w2 = nn.Parameter(torch.randn(128, 64) * 0.01)\n",
        "        self.b2 = nn.Parameter(torch.zeros(64))\n",
        "        self.w3 = nn.Parameter(torch.randn(64, 10) * 0.01)\n",
        "        self.b3 = nn.Parameter(torch.zeros(10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        # TODO: Do the forward pass using matrix multiplications and applying activation functions\n",
        "        x = torch.matmul(x, self.w1) + self.b1\n",
        "        x = torch.relu(x)\n",
        "        x = torch.matmul(x, self.w2) + self.b2\n",
        "        x = torch.relu(x)\n",
        "        x = torch.matmul(x, self.w3) + self.b3\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT4Rc3zVzsmY"
      },
      "source": [
        "### Training the manual model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuox_YANzsmY",
        "outputId": "079247e8-2099-48c7-c2c3-b4218ec7a105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training ManualNet\n",
            "Epoch 1, Loss: 526.7999\n",
            "Epoch 2, Loss: 232.0824\n",
            "Epoch 3, Loss: 159.6741\n",
            "Epoch 4, Loss: 125.1238\n",
            "Epoch 5, Loss: 103.1067\n",
            "Accuracy: 96.44%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining ManualNet\")\n",
        "# TODO: Create a ManualNet object and call it manual_model. Train and test it\n",
        "manual_model = ManualNet().to(device)\n",
        "optimizer_manual = optim.Adam(manual_model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train(manual_model, train_loader, optimizer_manual, loss_fn)\n",
        "test(manual_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYxpLgH_zsmZ"
      },
      "source": [
        "### Visualize the outputs of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "mQ478NjpzsmZ",
        "outputId": "94d0662d-743b-4787-f944-d62807d6d88b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def visualize(model, loader, n=5):\n",
        "    model.eval()\n",
        "    x, y = next(iter(loader))\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    preds = model(x).argmax(dim=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(x[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.title(f\"T:{y[i].item()} P:{preds[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# visualize(manual_model, test_loader) # Uncomment this later\n",
        "visualize(sequential_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_ymh-5LLyMY"
      },
      "source": [
        "## Assignment\n",
        "* Load and preprocess CIFAR100 dataset (not CIFAR10)\n",
        "* Build a feedforward network for it. You can experiment around with number of layers and and neurons in each layer and different activation functions\n",
        "* You are allowed to use nn.functional. (convolutions _might_ make your accuracy better)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KDvZGTIzsmZ"
      },
      "source": [
        "# Bonus Assignment\n",
        "* Try the solving the \"Titanic Survival Prediction\" dataset from kaggle"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}